import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import json
import joblib
from pathlib import Path

plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans', 'sans-serif']
sns.set_style("whitegrid")

class CombinedEvaluationVisualizer:
    def __init__(self):
        """í‰ê°€ ë° ì‹œê°í™” í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        # ë©”ì„œë“œë³„ ìƒ‰ìƒ ë° ë¼ë²¨ ì •ì˜
        self.methods = ['traditional', 'isolation_forest', 'one_class_svm']
        self.method_colors = {
            'traditional': '#FF6B6B',
            'isolation_forest': '#4ECDC4',
            'one_class_svm': '#45B7D1'
        }
        self.method_labels = {
            'traditional': 'Traditional Method',
            'isolation_forest': 'Isolation Forest',
            'one_class_svm': 'One-Class SVM'
        }
        
        # ê²½ë¡œ ì„¤ì •
        self.base_dir = Path(os.getcwd())
        self.charts_dir = self.base_dir / "charts" / "detection_performance"
        self.dummy_data_dir = self.base_dir / "dummy_data"
        self.models_dir = self.base_dir / "dummy_models"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.charts_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ë° í‰ê°€ ê²°ê³¼ ì €ì¥
        self.models = {}
        self.evaluation_results = {}
    
    def load_models(self):
        """í›ˆë ¨ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        print("ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.models = {'day': {}, 'night': {}}
        
        for time_period in ['day', 'night']:
            period_path = self.models_dir / time_period
            
            try:
                # ëª¨ë¸ë“¤ ë¡œë“œ (joblib ì‚¬ìš©)
                self.models[time_period]['scaler'] = joblib.load(period_path / 'scaler.pkl')
                self.models[time_period]['isolation_forest'] = joblib.load(period_path / 'isolation_forest.pkl')
                self.models[time_period]['one_class_svm'] = joblib.load(period_path / 'one_class_svm.pkl')
                
            except Exception as e:
                print(f"ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜ ({time_period}): {e}")
                continue
        
        print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

    def load_abnormal_hours(self, dataset_name):
        """abnormal_hour ë°ì´í„° ë¡œë“œ"""
        abnormal_hour_file = self.dummy_data_dir / "abnormal_hour" / f"{dataset_name}.csv"
        if abnormal_hour_file.exists():
            return pd.read_csv(abnormal_hour_file)
        return None

    def load_processed_data(self, dataset_name):
        """ì²˜ë¦¬ëœ íŠ¹ì„± ë°ì´í„° ë¡œë“œ"""
        processed_path = self.dummy_data_dir / "processed" / dataset_name
        
        if not processed_path.exists():
            print(f"ê²½ë¡œ ì—†ìŒ: {processed_path}")
            return {}
        
        features = {}
        for time_period in ['day', 'night']:
            features[time_period] = {}
            
            # ê° íŠ¹ì„± íŒŒì¼ ë¡œë“œ
            feature_files = {
                'inactive_total': f'{time_period}_inactive_total.csv',
                'inactive_room': f'{time_period}_inactive_room.csv',
                'toggle_total': f'{time_period}_toggle_total.csv',
                'toggle_room': f'{time_period}_toggle_room.csv',
                'on_ratio_room': f'{time_period}_on_ratio_room.csv',
                'kitchen_usage_rate': f'{time_period}_kitchen_usage_rate.csv'
            }
            
            if time_period == 'night':
                feature_files['bathroom_usage'] = 'night_bathroom_usage.csv'
            
            for feature_key, filename in feature_files.items():
                file_path = processed_path / filename
                if file_path.exists():
                    features[time_period][feature_key] = pd.read_csv(file_path)
        
        return features

    def create_feature_vector_for_user(self, dataset_features, time_period, user_id):
        """íŠ¹ì • ì‚¬ìš©ìì— ëŒ€í•œ íŠ¹ì„± ë²¡í„° ìƒì„±"""
        if time_period == 'day':
            # Day ëª¨ë¸: 15ê°œ íŠ¹ì§•
            expected_features = [
                'day_inactive_total',
                'day_inactive_room_01', 'day_inactive_room_02', 'day_inactive_room_03', 'day_inactive_room_04',
                'day_toggle_total', 
                'day_toggle_room_01', 'day_toggle_room_02', 'day_toggle_room_03', 'day_toggle_room_04',
                'day_on_ratio_room_01', 'day_on_ratio_room_02', 'day_on_ratio_room_03', 'day_on_ratio_room_04',
                'day_kitchen_usage_rate'
            ]
        else:  # night
            # Night ëª¨ë¸: 16ê°œ íŠ¹ì§•
            expected_features = [
                'night_inactive_total',
                'night_inactive_room_01', 'night_inactive_room_02', 'night_inactive_room_03', 'night_inactive_room_04', 
                'night_toggle_total',
                'night_toggle_room_01', 'night_toggle_room_02', 'night_toggle_room_03', 'night_toggle_room_04',
                'night_on_ratio_room_01', 'night_on_ratio_room_02', 'night_on_ratio_room_03', 'night_on_ratio_room_04',
                'night_kitchen_usage_rate',
                'night_bathroom_usage'
            ]
        
        user_feature_vector = []
        
        for expected_feature in expected_features:
            # íŠ¹ì„±ëª…ì—ì„œ time_period ì ‘ë‘ì‚¬ ì œê±°í•˜ì—¬ íŒŒì¼ëª…ê³¼ ë§¤ì¹­
            base_feature = expected_feature.replace(f'{time_period}_', '')
            
            # ë°©ë³„ íŠ¹ì§• ì²˜ë¦¬ (01, 02, 03, 04)
            if base_feature.endswith('_01') or base_feature.endswith('_02') or base_feature.endswith('_03') or base_feature.endswith('_04'):
                room_num = base_feature[-2:]  # 01, 02, 03, 04
                feature_type = base_feature[:-3]  # inactive_room, toggle_room, on_ratio_room
                
                if feature_type in dataset_features[time_period]:
                    df = dataset_features[time_period][feature_type]
                    user_data = df[df['User'] == user_id]
                    
                    if len(user_data) > 0 and room_num in df.columns:
                        # í•´ë‹¹ ë°©ì˜ í‰ê· ê°’ ì‚¬ìš©
                        value = user_data[room_num].mean()
                        user_feature_vector.append(value)
                    else:
                        user_feature_vector.append(0.0)
                else:
                    user_feature_vector.append(0.0)
            
            # ì „ì²´ íŠ¹ì§• ì²˜ë¦¬ (total, kitchen_usage_rate, bathroom_usage)
            else:
                if base_feature in dataset_features[time_period]:
                    df = dataset_features[time_period][base_feature]
                    user_data = df[df['User'] == user_id]
                    
                    if len(user_data) > 0:
                        # User, Dateë¥¼ ì œì™¸í•œ ì²« ë²ˆì§¸ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì‚¬ìš©
                        numeric_cols = [col for col in user_data.columns 
                                      if col not in ['User', 'Date'] and not col.startswith('Unnamed')]
                        if len(numeric_cols) > 0:
                            # í‰ê· ê°’ ì‚¬ìš©
                            value = user_data[numeric_cols[0]].mean()
                            user_feature_vector.append(value)
                        else:
                            user_feature_vector.append(0.0)
                    else:
                        user_feature_vector.append(0.0)  # ì‚¬ìš©ì ë°ì´í„° ì—†ìŒ
                else:
                    user_feature_vector.append(0.0)  # ê¸°ë³¸ê°’
        
        return np.array(user_feature_vector).reshape(1, -1)

    def find_last_led_change(self, dataset_name, user_id):
        """raw ë°ì´í„°ì—ì„œ ë§ˆì§€ë§‰ LED ë³€í™” ì‹œì  ì°¾ê¸°"""
        try:
            raw_file = self.dummy_data_dir / "raw" / f"{dataset_name}.csv"
            
            # ì‚¬ìš©ì ë°ì´í„°ë§Œ í•„í„°ë§í•´ì„œ ì½ê¸°
            import pandas as pd
            df = pd.read_csv(raw_file)
            
            user_data = df[df['User'] == user_id].copy()
            
            if len(user_data) == 0:
                return None
                
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
            user_data['Timestamp'] = pd.to_datetime(user_data['Timestamp'])
            user_data = user_data.sort_values('Timestamp')
            
            # ì´ì „ ìƒíƒœì™€ ë¹„êµí•´ì„œ ë³€í™” ì‹œì  ì°¾ê¸°
            last_change_time = None
            prev_state = None
            change_count = 0
            
            for _, row in user_data.iterrows():
                current_state = (row['01'], row['02'], row['03'], row['04'])
                
                if prev_state is not None and current_state != prev_state:
                    last_change_time = row['Timestamp']
                    change_count += 1
                
                prev_state = current_state
            
            return last_change_time
            
        except Exception as e:
            print(f"Error finding last LED change for user {user_id}: {e}")
            return None

    def traditional_detection_time(self, dataset_name, user_id, abnormal_hour):
        """ì „í†µì  ë°©ë²•: ë§ˆì§€ë§‰ LED ë³€í™” + 24ì‹œê°„ í›„ íƒì§€"""
        last_change = self.find_last_led_change(dataset_name, user_id)
        
        if last_change is None:
            return 72  # ë°ì´í„° ì—†ìœ¼ë©´ ë¯¸íƒì§€
        
        # Raw ë°ì´í„°ì—ì„œ ì²« ë²ˆì§¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸° (ë°ì´í„° ì‹œì‘ ë‚ ì§œ)
        try:
            raw_file = self.dummy_data_dir / "raw" / f"{dataset_name}.csv"
            df = pd.read_csv(raw_file)
            user_data = df[df['User'] == user_id].copy()
            
            if len(user_data) == 0:
                return 72
            
            user_data['Timestamp'] = pd.to_datetime(user_data['Timestamp'])
            first_timestamp = user_data['Timestamp'].min()
            
            # abnormal_hourë¥¼ ì²« ë²ˆì§¸ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
            abnormal_datetime = first_timestamp.replace(
                hour=int(abnormal_hour), 
                minute=int((abnormal_hour % 1) * 60), 
                second=0, 
                microsecond=0
            )
            
        except Exception as e:
            print(f"Error getting first timestamp for user {user_id}: {e}")
            return 72
        
        # ë§ˆì§€ë§‰ ë³€í™” ì‹œì  + 24ì‹œê°„ = íƒì§€ ì‹œì 
        detection_time = last_change + pd.Timedelta(hours=24)
        
        # abnormal_hourë¶€í„° íƒì§€ ì‹œì ê¹Œì§€ì˜ ì‹¤ì œ ì‹œê°„ì°¨ (ì‹œê°„ ë‹¨ìœ„)
        time_diff_hours = (detection_time - abnormal_datetime).total_seconds() / 3600
        
        # ìŒìˆ˜ì¸ ê²½ìš° (abnormal_hourê°€ íƒì§€ë³´ë‹¤ ëŠ¦ìŒ) 72ì‹œê°„ìœ¼ë¡œ ì„¤ì •
        if time_diff_hours < 0:
            return 72
        
        # 72ì‹œê°„ ì´ë‚´ì— íƒì§€ë˜ë©´ ì„±ê³µ
        return time_diff_hours if time_diff_hours <= 72 else 72

    def predict_anomaly(self, features, time_period, method):
        """íŠ¹ì • ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ì˜ˆì¸¡ (ML ëª¨ë¸ë§Œ)"""        
        if method in ['isolation_forest', 'one_class_svm']:
            if method in self.models[time_period]:
                model = self.models[time_period][method]
                scaler = self.models[time_period]['scaler']
                
                # ì •ê·œí™” ë° ì˜ˆì¸¡
                features_scaled = scaler.transform(features)
                prediction = model.predict(features_scaled)[0]
                
                # sklearnì˜ -1(ì´ìƒ), 1(ì •ìƒ)ì„ 1(ì´ìƒ), 0(ì •ìƒ)ìœ¼ë¡œ ë³€í™˜
                result = 1 if prediction == -1 else 0
                
                return result
        
        return 0

    def evaluate_user_detection(self, dataset_name, user_id, abnormal_hour, is_normal=False):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ì´ìƒ íƒì§€ í‰ê°€"""
        dataset_features = self.load_processed_data(dataset_name)
        
        # abnormal_hour ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘ ëª¨ë¸ ê²°ì • (normalì¸ ê²½ìš° ì„ì˜ ì‹œì‘ì )
        if is_normal:
            # ì •ìƒ ë°ì´í„°ëŠ” ì„ì˜ ì‹œì ë¶€í„° ì‹œì‘ (ì˜¤ì „ 6ì‹œë¡œ ê³ ì •)
            start_model = 'night'
            start_time = 6
        else:
            if abnormal_hour < 6:  # 0~5ì‹œ: night ëª¨ë¸ë¶€í„°
                start_model = 'night'
                start_time = 6  # ë‹¤ìŒ ì˜¤ì „ 6ì‹œë¶€í„° ì‹œì‘
            elif abnormal_hour < 18:  # 6~17ì‹œ: day ëª¨ë¸ë¶€í„°  
                start_model = 'day'
                start_time = 18  # ë‹¤ìŒ ì˜¤í›„ 6ì‹œë¶€í„° ì‹œì‘
            else:  # 18~23ì‹œ: ìµì¼ night ëª¨ë¸ë¶€í„°
                start_model = 'night'
                start_time = 6 + 24  # ìµì¼ ì˜¤ì „ 6ì‹œë¶€í„° ì‹œì‘
        
        detection_results = {}
        
        # ê° ë°©ë²•ë³„ë¡œ í‰ê°€
        for method in ['traditional', 'isolation_forest', 'one_class_svm']:
            if method == 'traditional':
                # ì „í†µì  ë°©ë²•: raw ë°ì´í„°ì—ì„œ ë§ˆì§€ë§‰ LED ë³€í™” + 24ì‹œê°„
                if is_normal:
                    # ì •ìƒ ë°ì´í„°ì—ì„œëŠ” ì‹¤ì œ LED ë³€í™”ë¥¼ í™•ì¸í•´ì„œ íƒì§€ ì—¬ë¶€ ê²°ì •
                    detection_time = self.traditional_detection_time(dataset_name, user_id, 0)  # abnormal_hour=0ìœ¼ë¡œ ì„¤ì •
                    detected = detection_time < 72  # 72ì‹œê°„ ë‚´ì— íƒì§€ë˜ë©´ False Positive
                else:
                    detection_time = self.traditional_detection_time(dataset_name, user_id, abnormal_hour)
                    detected = detection_time < 72
                
                detection_results[method] = {
                    'detected': detected,
                    'detection_time': detection_time
                }
                
            else:
                # ML ë°©ë²•: 6ì‹œê°„ë§ˆë‹¤ ê²€ì‚¬
                detected = False
                detection_time = None
                current_time = start_time
                current_model = start_model
                
                # ìµœëŒ€ 72ì‹œê°„(12íšŒ ê²€ì‚¬) ë™ì•ˆ 6ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ê²€ì‚¬
                for check_num in range(12):  # 72ì‹œê°„ / 6ì‹œê°„ = 12íšŒ
                    try:
                        features = self.create_feature_vector_for_user(dataset_features, current_model, user_id)
                        
                        # ì´ìƒì¹˜ ì˜ˆì¸¡
                        is_anomaly = self.predict_anomaly(features, current_model, method)
                        
                        if is_anomaly:
                            detected = True
                            # íƒì§€ ì‹œê°„ ê³„ì‚°
                            if is_normal:
                                detection_time = check_num * 6  # ì •ìƒ ë°ì´í„°ëŠ” ì‹œì‘ì ë¶€í„° ê³„ì‚°
                            else:
                                # abnormal_hourë¡œë¶€í„° ì–¼ë§ˆë‚˜ ì§€ë‚¬ëŠ”ì§€
                                if current_time >= 24:
                                    actual_time = current_time - 24
                                else:
                                    actual_time = current_time
                                
                                detection_time = actual_time - abnormal_hour
                                if detection_time < 0:
                                    detection_time += 24  # ë‹¤ìŒë‚ 
                            
                            break
                    except Exception as e:
                        print(f"Error processing user {user_id} with {method}: {e}")
                        break
                    
                    # ë‹¤ìŒ ê²€ì‚¬ ì‹œê°„ìœ¼ë¡œ ì´ë™
                    current_time += 6
                    if current_time >= 48:  # 2ì¼ì„ ë„˜ì–´ê°€ë©´ ë‹¤ì‹œ 0ë¶€í„°
                        current_time -= 24
                    elif current_time >= 24:
                        current_time = current_time  # ë‹¤ìŒë‚  ìœ ì§€
                    
                    # ëª¨ë¸ ì „í™˜ (6ì‹œ -> night, 18ì‹œ -> day)
                    effective_time = current_time % 24
                    if effective_time == 6:
                        current_model = 'night'
                    elif effective_time == 18:
                        current_model = 'day'
                
                detection_results[method] = {
                    'detected': detected,
                    'detection_time': detection_time if detected else 72  # ë¯¸íƒì§€ì‹œ 72ì‹œê°„
                }
        
        return detection_results

    def evaluate_dataset(self, dataset_name, is_normal=False):
        """ë°ì´í„°ì…‹ ì „ì²´ í‰ê°€"""
        print(f"ë°ì´í„°ì…‹ í‰ê°€ ì¤‘: {dataset_name}")
        
        if is_normal:
            # ì •ìƒ ë°ì´í„°ëŠ” abnormal_hour ì—†ì´ ì‚¬ìš©ì ëª©ë¡ë§Œ ê°€ì ¸ì˜¤ê¸°
            dataset_features = self.load_processed_data(dataset_name)
            if 'day' in dataset_features and 'inactive_total' in dataset_features['day']:
                users = dataset_features['day']['inactive_total']['User'].unique()
                abnormal_hours_data = pd.DataFrame({'User': users, 'abnormal_hour': [6] * len(users)})  # ì„ì˜ê°’
            else:
                print(f"ì •ìƒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {dataset_name}")
                return {}
        else:
            # abnormal_hour ë°ì´í„° ë¡œë“œ
            abnormal_hours_data = self.load_abnormal_hours(dataset_name)
            if abnormal_hours_data is None:
                print(f"abnormal_hour ë°ì´í„° ì—†ìŒ: {dataset_name}")
                return {}
        
        # ê° ì‚¬ìš©ìë³„ í‰ê°€
        all_results = {}
        for _, row in abnormal_hours_data.iterrows():
            user_id = row['User']
            abnormal_hour = row['abnormal_hour'] if not is_normal else 0
            
            user_results = self.evaluate_user_detection(dataset_name, user_id, abnormal_hour, is_normal)
            all_results[user_id] = user_results
        
        # ì§‘ê³„ ê²°ê³¼ ê³„ì‚°
        summary = {}
        for method in ['traditional', 'isolation_forest', 'one_class_svm']:
            detected_count = sum(1 for r in all_results.values() if r[method]['detected'])
            total_count = len(all_results)
            
            detection_times = [r[method]['detection_time'] for r in all_results.values() if r[method]['detected']]
            avg_detection_time = np.mean(detection_times) if detection_times else 72
            
            if is_normal:
                # ì •ìƒ ë°ì´í„°ì—ì„œ íƒì§€ë˜ë©´ False Positive
                false_positive_rate = (detected_count / total_count) * 100 if total_count > 0 else 0
                detection_rate_72h = 0  # ì •ìƒ ë°ì´í„°ëŠ” íƒì§€ìœ¨ ê³„ì‚° ì•ˆí•¨
            else:
                detection_rate_72h = (detected_count / total_count) * 100 if total_count > 0 else 0
                false_positive_rate = 0
            
            summary[method] = {
                'detection_rate_72h': detection_rate_72h,
                'avg_detection_time': avg_detection_time,
                'detected_count': detected_count,
                'total_count': total_count,
                'false_positive_rate': false_positive_rate
            }
            
            if is_normal:
                print(f"  {method}: {detected_count}/{total_count} False Positive ({false_positive_rate:.1f}%)")
            else:
                print(f"  {method}: {detected_count}/{total_count} íƒì§€ ({detection_rate_72h:.1f}%), í‰ê·  íƒì§€ ì‹œê°„: {avg_detection_time:.1f}h")
        
        return {
            'summary': summary,
            'detailed': all_results
        }

    def generate_evaluation_data(self):
        """ì‹¤ì œ í‰ê°€ ë°ì´í„° ìƒì„±"""
        print("ì‹¤ì œ ëª¨ë¸ê³¼ abnormal_hour ë°ì´í„°ë¡œ í‰ê°€ ìˆ˜í–‰ ì¤‘...")
        
        # ë°ì´í„°ì…‹ ëª©ë¡
        datasets = {
            'immediate': 'immediate_abnormal_test_dataset',
            'rapid': 'rapid_abnormal_test_dataset', 
            'gradual': 'gradual_abnormal_test_dataset'
        }
        
        evaluation_results = {
            'detection_72h': {},
            'avg_detection_time': {},
            'time_based_detection': {'all': {}},
            'false_positive': {}
        }
        
        # ê° ë°ì´í„°ì…‹ í‰ê°€ (ë¹„ì •ìƒ ë°ì´í„°)
        all_dataset_results = {}
        for dataset_type, dataset_name in datasets.items():
            dataset_results = self.evaluate_dataset(dataset_name, is_normal=False)
            all_dataset_results[dataset_type] = dataset_results
            
            # ê²°ê³¼ ì €ì¥
            for method in ['traditional', 'isolation_forest', 'one_class_svm']:
                if dataset_type not in evaluation_results['detection_72h']:
                    evaluation_results['detection_72h'][dataset_type] = {}
                if dataset_type not in evaluation_results['avg_detection_time']:
                    evaluation_results['avg_detection_time'][dataset_type] = {}
                
                summary = dataset_results['summary'][method]
                evaluation_results['detection_72h'][dataset_type][method] = summary['detection_rate_72h']
                evaluation_results['avg_detection_time'][dataset_type][method] = summary['avg_detection_time']
        
        # ì •ìƒ ë°ì´í„°ë¡œ False Positive í‰ê°€
        print("\nì •ìƒ ë°ì´í„°ë¡œ False Positive í‰ê°€ ì¤‘...")
        normal_results = self.evaluate_dataset('normal_test_dataset', is_normal=True)
        
        for method in ['traditional', 'isolation_forest', 'one_class_svm']:
            fp_rate = normal_results['summary'][method]['false_positive_rate']
            
            # ê° ë°ì´í„°ì…‹ì— ë™ì¼í•œ FP rate ì ìš©
            for dataset_type in ['immediate', 'rapid', 'gradual']:
                if dataset_type not in evaluation_results['false_positive']:
                    evaluation_results['false_positive'][dataset_type] = {}
                evaluation_results['false_positive'][dataset_type][method] = fp_rate
        
        # ì „ì²´ í‰ê·  ê³„ì‚°
        evaluation_results['detection_72h']['all'] = {}
        evaluation_results['avg_detection_time']['all'] = {}
        evaluation_results['false_positive']['all'] = {}
        
        for method in ['traditional', 'isolation_forest', 'one_class_svm']:
            # ì „ì²´ í‰ê·  ê³„ì‚°
            detection_rates = [evaluation_results['detection_72h'][dt][method] for dt in ['immediate', 'rapid', 'gradual']]
            detection_times = [evaluation_results['avg_detection_time'][dt][method] for dt in ['immediate', 'rapid', 'gradual']]
            
            evaluation_results['detection_72h']['all'][method] = np.mean(detection_rates)
            evaluation_results['avg_detection_time']['all'][method] = np.mean(detection_times)
            evaluation_results['false_positive']['all'][method] = normal_results['summary'][method]['false_positive_rate']
        
        # ì‹œê°„ëŒ€ë³„ íƒì§€ìœ¨ ê³„ì‚° (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        for time_window in [3, 6, 12, 24]:
            evaluation_results['time_based_detection']['all'][time_window] = {}
            
            for method in ['traditional', 'isolation_forest', 'one_class_svm']:
                total_detected = 0
                total_users = 0
                
                # ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ í•´ë‹¹ ì‹œê°„ ë‚´ íƒì§€ëœ ì‚¬ìš©ì ìˆ˜ ê³„ì‚°
                for dataset_type in ['immediate', 'rapid', 'gradual']:
                    detailed_results = all_dataset_results[dataset_type]['detailed']
                    
                    for user_id, user_result in detailed_results.items():
                        total_users += 1
                        if user_result[method]['detected'] and user_result[method]['detection_time'] <= time_window:
                            total_detected += 1
                
                detection_rate = (total_detected / total_users * 100) if total_users > 0 else 0
                evaluation_results['time_based_detection']['all'][time_window][method] = detection_rate
        
        print("ì‹¤ì œ í‰ê°€ ì™„ë£Œ")
        return evaluation_results

    def create_72h_detection_rate_by_dataset(self):
        """72ì‹œê°„ ë‚´ ë°ì´í„°ì…‹ë³„ ê°ì§€ìœ¨ ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        datasets = ['Immediate', 'Rapid', 'Gradual']
        dataset_keys = ['immediate', 'rapid', 'gradual']
        
        detection_72h = {
            'traditional': [self.evaluation_results['detection_72h'][dk]['traditional'] for dk in dataset_keys],
            'isolation_forest': [self.evaluation_results['detection_72h'][dk]['isolation_forest'] for dk in dataset_keys],
            'one_class_svm': [self.evaluation_results['detection_72h'][dk]['one_class_svm'] for dk in dataset_keys]
        }
        
        x = np.arange(len(datasets))
        width = 0.25
        
        for i, method in enumerate(self.methods):
            rates = detection_72h[method]
            bars = ax.bar(x + (i - 1) * width, rates, width, label=self.method_labels[method], 
                        color=self.method_colors[method], alpha=0.8)
            
            for j, bar in enumerate(bars):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                      f'{height:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('Dataset', fontsize=12)
        ax.set_ylabel('72-hour Detection Rate (%)', fontsize=12)
        ax.set_title('Detection Rate within 72 Hours by Dataset', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(datasets)
        ax.set_ylim(0, 105)
        ax.grid(axis='y', alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, '72h_detection_rate_by_dataset.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ 72-hour detection rate by dataset ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_72h_detection_rate_all(self):
        """72ì‹œê°„ ë‚´ ì „ì²´ ê°ì§€ìœ¨ ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(8, 6))
        
        methods = ['Traditional', 'Isolation Forest', 'One-Class SVM']
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        
        detection_rates_72h = [
            self.evaluation_results['detection_72h']['all']['traditional'],
            self.evaluation_results['detection_72h']['all']['isolation_forest'],
            self.evaluation_results['detection_72h']['all']['one_class_svm']
        ]
        
        bars = ax.bar(methods, detection_rates_72h, color=colors, alpha=0.8)
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                  f'{height:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        ax.set_ylabel('Detection Rate (%)', fontsize=12)
        ax.set_title('Overall 72-hour Detection Rate', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 105)
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, '72h_detection_rate_all.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ 72-hour detection rate (All) ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_time_based_detection_rate(self):
        """ì‹œê°„ë³„ ëˆ„ì  ê°ì§€ìœ¨ ì°¨íŠ¸ - ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ë³€ê²½"""
        fig, ax = plt.subplots(figsize=(12, 6))
        
        time_windows = [3, 6, 12, 24]
        time_labels = ['3h', '6h', '12h', '24h']
        
        # ë°ì´í„° ì¤€ë¹„
        detection_by_time = {
            'traditional': [self.evaluation_results['time_based_detection']['all'][tw]['traditional'] for tw in time_windows],
            'isolation_forest': [self.evaluation_results['time_based_detection']['all'][tw]['isolation_forest'] for tw in time_windows],
            'one_class_svm': [self.evaluation_results['time_based_detection']['all'][tw]['one_class_svm'] for tw in time_windows]
        }
        
        x = np.arange(len(time_windows))
        width = 0.25
        
        for i, method in enumerate(self.methods):
            rates = detection_by_time[method]
            bars = ax.bar(x + (i - 1) * width, rates, width, label=self.method_labels[method], 
                        color=self.method_colors[method], alpha=0.8)
            
            for j, bar in enumerate(bars):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                      f'{height:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('Time Window', fontsize=12)
        ax.set_ylabel('Cumulative Detection Rate (%)', fontsize=12)
        ax.set_title('Detection Rate by Time Window', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(time_labels)
        ax.set_ylim(0, 105)
        ax.grid(axis='y', alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, 'time_based_detection_rate.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ Time-based detection rate ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_false_positive_by_dataset(self):
        """ë°ì´í„°ì…‹ë³„ False Positive ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        datasets = ['Immediate', 'Rapid', 'Gradual']
        dataset_keys = ['immediate', 'rapid', 'gradual']
        
        false_positive = {
            'traditional': [self.evaluation_results['false_positive'][dk]['traditional'] for dk in dataset_keys],
            'isolation_forest': [self.evaluation_results['false_positive'][dk]['isolation_forest'] for dk in dataset_keys],
            'one_class_svm': [self.evaluation_results['false_positive'][dk]['one_class_svm'] for dk in dataset_keys]
        }
        
        x = np.arange(len(datasets))
        width = 0.25
        
        for i, method in enumerate(self.methods):
            rates = false_positive[method]
            bars = ax.bar(x + (i - 1) * width, rates, width, label=self.method_labels[method], 
                        color=self.method_colors[method], alpha=0.8)
            
            for j, bar in enumerate(bars):
                height = bar.get_height()
                if height > 0:
                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                          f'{height:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('Dataset', fontsize=12)
        ax.set_ylabel('False Positive Rate (%)', fontsize=12)
        ax.set_title('False Positive Rate by Dataset', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(datasets)
        ax.set_ylim(0, max(5, max([max(rates) for rates in false_positive.values()]) + 1))
        ax.grid(axis='y', alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, 'false_positive_by_dataset.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ False positive rate by dataset ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_false_positive_all(self):
        """ì „ì²´ False Positive ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(8, 6))
        
        methods = ['Traditional', 'Isolation Forest', 'One-Class SVM']
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        
        false_positive_rates = [
            self.evaluation_results['false_positive']['all']['traditional'],
            self.evaluation_results['false_positive']['all']['isolation_forest'],
            self.evaluation_results['false_positive']['all']['one_class_svm']
        ]
        
        bars = ax.bar(methods, false_positive_rates, color=colors, alpha=0.8)
        

        
        ax.set_ylabel('False Positive Rate (%)', fontsize=12)
        ax.set_title('Overall False Positive Rate', fontsize=14, fontweight='bold')
        max_rate = max(false_positive_rates) if any(r > 0 for r in false_positive_rates) else 5
        ax.set_ylim(0, max(5, max_rate + 1))
        
        # 0%ì¼ ë•Œë„ í…ìŠ¤íŠ¸ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                  f'{height:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, 'false_positive_all.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ False positive rate (All) ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_avg_detection_time_by_dataset(self):
        """ë°ì´í„°ì…‹ë³„ í‰ê·  íƒì§€ ì‹œê°„ ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(10, 6))
        
        datasets = ['Immediate', 'Rapid', 'Gradual']
        dataset_keys = ['immediate', 'rapid', 'gradual']
        
        avg_detection_time = {
            'traditional': [self.evaluation_results['avg_detection_time'][dk]['traditional'] for dk in dataset_keys],
            'isolation_forest': [self.evaluation_results['avg_detection_time'][dk]['isolation_forest'] for dk in dataset_keys],
            'one_class_svm': [self.evaluation_results['avg_detection_time'][dk]['one_class_svm'] for dk in dataset_keys]
        }
        
        x = np.arange(len(datasets))
        width = 0.25
        
        for i, method in enumerate(self.methods):
            times = avg_detection_time[method]
            bars = ax.bar(x + (i - 1) * width, times, width, label=self.method_labels[method], 
                        color=self.method_colors[method], alpha=0.8)
            
            for j, bar in enumerate(bars):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                      f'{height:.1f}h', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('Dataset', fontsize=12)
        ax.set_ylabel('Average Detection Time (hours)', fontsize=12)
        ax.set_title('Average Detection Time by Dataset', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(datasets)
        ax.set_ylim(0, 75)
        ax.grid(axis='y', alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, 'avg_detection_time_by_dataset.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ Average detection time by dataset ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")

    def create_avg_detection_time_all(self):
        """ì „ì²´ í‰ê·  íƒì§€ ì‹œê°„ ì°¨íŠ¸"""
        fig, ax = plt.subplots(figsize=(8, 6))
        
        methods = ['Traditional', 'Isolation Forest', 'One-Class SVM']
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        
        avg_detection_times = [
            self.evaluation_results['avg_detection_time']['all']['traditional'],
            self.evaluation_results['avg_detection_time']['all']['isolation_forest'],
            self.evaluation_results['avg_detection_time']['all']['one_class_svm']
        ]
        
        bars = ax.bar(methods, avg_detection_times, color=colors, alpha=0.8)
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                  f'{height:.1f}h', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        ax.set_ylabel('Average Detection Time (hours)', fontsize=12)
        ax.set_title('Overall Average Detection Time', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 75)
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.charts_dir, 'avg_detection_time_all.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ Average detection time (All) ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")



    def run_complete_evaluation(self):
        """ì „ì²´ í‰ê°€ ë° ì‹œê°í™” ì‹¤í–‰"""
        print("=== í†µí•© í‰ê°€ ë° ì‹œê°í™” ì‹œìŠ¤í…œ ì‹œì‘ ===")
        
        # 1. ëª¨ë¸ ë¡œë“œ
        self.load_models()
        
        # 2. ì‹¤ì œ í‰ê°€ ë°ì´í„° ìƒì„±
        self.evaluation_results = self.generate_evaluation_data()
        
        # 3. ì‹œê°í™” ìƒì„±
        print("\n=== ì‹œê°í™” ìƒì„± ì¤‘ ===")
        self.create_72h_detection_rate_by_dataset()
        self.create_72h_detection_rate_all()
        self.create_time_based_detection_rate()
        self.create_false_positive_by_dataset()
        self.create_false_positive_all()
        self.create_avg_detection_time_by_dataset()
        self.create_avg_detection_time_all()
        
        # 4. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\n=== ëª¨ë“  ì‘ì—… ì™„ë£Œ ===")
        print(f"ğŸ“Š ì°¨íŠ¸ ì €ì¥ ìœ„ì¹˜: {self.charts_dir}")
        
        print("\n=== ì£¼ìš” ê²°ê³¼ ìš”ì•½ ===")
        print("72ì‹œê°„ ë‚´ ì „ì²´ ê°ì§€ìœ¨:")
        for method_key, method_name in [('traditional', 'Traditional Method'), 
                                       ('isolation_forest', 'Isolation Forest'), 
                                       ('one_class_svm', 'One-Class SVM')]:
            rate = self.evaluation_results['detection_72h']['all'][method_key]
            print(f"  - {method_name}: {rate:.1f}%")
        
        print("\ní‰ê·  íƒì§€ ì‹œê°„:")
        for method_key, method_name in [('traditional', 'Traditional Method'), 
                                       ('isolation_forest', 'Isolation Forest'), 
                                       ('one_class_svm', 'One-Class SVM')]:
            time = self.evaluation_results['avg_detection_time']['all'][method_key]
            print(f"  - {method_name}: {time:.1f}ì‹œê°„")
        
        print("\nFalse Positive Rate:")
        for method_key, method_name in [('traditional', 'Traditional Method'), 
                                       ('isolation_forest', 'Isolation Forest'), 
                                       ('one_class_svm', 'One-Class SVM')]:
            fp_rate = self.evaluation_results['false_positive']['all'][method_key]
            print(f"  - {method_name}: {fp_rate:.1f}%")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    evaluator = CombinedEvaluationVisualizer()
    evaluator.run_complete_evaluation()

if __name__ == "__main__":
    main() 